# Streamlit-Ollama-Llama3.2-Chat

This repository provides a chatbot application powered by **Llama 3.2** using **Streamlit**. The chatbot is designed to generate responses to user inputs efficiently, utilizing the power of advanced language models.

---

## Features

- **Interactive Chat Interface**: Users can enter prompts and get responses in real time.
- **Powered by Llama 3.2**: Utilizes the cutting-edge Llama 3.2 model from Ollama for natural language understanding and response generation.
- **GPU Support**: Automatically detects and uses GPU if available for faster processing.

---

## Prerequisites

- Python 3.8 or higher
- CUDA-enabled GPU (optional for faster performance)

---

## Installation

1. Clone the repository:
```bash
git clone https://github.com/zenklinov/Streamlit-Ollama-Llama3.2-Chat.git
cd Streamlit-Ollama-Llama3.2-Chat
```
2. Ensure you have Ollama and the llama3.2 model installed locally.

## Usage

1. Change directory to the file.

2. Run the Streamlit app:
```bash
streamlit run app.py
```

3. Enter your prompt in the text area and click the "Generate" button to see the response from the chatbot.
